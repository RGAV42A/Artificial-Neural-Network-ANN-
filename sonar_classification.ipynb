{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9  ...      51      52      53      54      55      56      57      58  \\\n",
      "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
      "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
      "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
      "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
      "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
      "\n",
      "       59  60  \n",
      "0  0.0032   R  \n",
      "1  0.0044   R  \n",
      "2  0.0078   R  \n",
      "3  0.0117   R  \n",
      "4  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - 21s 112ms/step - loss: 0.6485 - acc: 0.6452\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 8s 41ms/step - loss: 0.5237 - acc: 0.7312\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 9s 48ms/step - loss: 0.4539 - acc: 0.7742\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 10s 53ms/step - loss: 0.4005 - acc: 0.8441\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 7s 38ms/step - loss: 0.3600 - acc: 0.8602\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 5s 26ms/step - loss: 0.3212 - acc: 0.8763\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 12s 63ms/step - loss: 0.2922 - acc: 0.9032\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 8s 41ms/step - loss: 0.2649 - acc: 0.9086\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 6s 34ms/step - loss: 0.2426 - acc: 0.9247\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 11s 60ms/step - loss: 0.2215 - acc: 0.9516\n",
      "22/22 [==============================] - 5s 214ms/step\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 10s 52ms/step - loss: 0.4679 - acc: 0.7754\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.4109 - acc: 0.8182\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 10s 51ms/step - loss: 0.3592 - acc: 0.8717\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 12s 64ms/step - loss: 0.3184 - acc: 0.8770\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 0.2854 - acc: 0.9144\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 3s 18ms/step - loss: 0.2572 - acc: 0.9198\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 4s 23ms/step - loss: 0.2323 - acc: 0.9412\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 9s 48ms/step - loss: 0.2104 - acc: 0.9572\n",
      "21/21 [==============================] - 4s 171ms/step\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 28s 152ms/step - loss: 0.7108 - acc: 0.5722\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 10s 55ms/step - loss: 0.5612 - acc: 0.7380\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 7s 39ms/step - loss: 0.4791 - acc: 0.7807\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 5s 29ms/step - loss: 0.4210 - acc: 0.8289\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 12s 62ms/step - loss: 0.3755 - acc: 0.8396\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 8s 43ms/step - loss: 0.3378 - acc: 0.8663\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 7s 38ms/step - loss: 0.3048 - acc: 0.8824\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 0.2755 - acc: 0.9091\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 11s 58ms/step - loss: 0.2535 - acc: 0.9251\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 8s 44ms/step - loss: 0.2304 - acc: 0.9251\n",
      "21/21 [==============================] - 4s 185ms/step\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 27s 147ms/step - loss: 0.8068 - acc: 0.5508\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 10s 51ms/step - loss: 0.5718 - acc: 0.7005\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 5s 27ms/step - loss: 0.4866 - acc: 0.7540\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 11s 56ms/step - loss: 0.4270 - acc: 0.8021\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 9s 49ms/step - loss: 0.3817 - acc: 0.8503\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.3428 - acc: 0.8824\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.3093 - acc: 0.9251\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 12s 64ms/step - loss: 0.2815 - acc: 0.9305\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 9s 48ms/step - loss: 0.2586 - acc: 0.9305\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 4s 23ms/step - loss: 0.2390 - acc: 0.9358\n",
      "21/21 [==============================] - 4s 186ms/step\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 29s 155ms/step - loss: 0.7662 - acc: 0.5241\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 12s 62ms/step - loss: 0.5595 - acc: 0.7166\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 10s 55ms/step - loss: 0.4533 - acc: 0.8128\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 5s 28ms/step - loss: 0.3817 - acc: 0.8610\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.3325 - acc: 0.9091\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 15s 78ms/step - loss: 0.2905 - acc: 0.9305\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 9s 47ms/step - loss: 0.2602 - acc: 0.9358\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 10s 54ms/step - loss: 0.2324 - acc: 0.9412\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 11s 56ms/step - loss: 0.2104 - acc: 0.9519\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 8s 44ms/step - loss: 0.1912 - acc: 0.9519\n",
      "21/21 [==============================] - 5s 249ms/step\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 0.6499 - acc: 0.5936\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 6s 31ms/step - loss: 0.5185 - acc: 0.7647\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 13s 69ms/step - loss: 0.4452 - acc: 0.7914\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 9s 48ms/step - loss: 0.3919 - acc: 0.8449\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.3508 - acc: 0.8717\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 0.3179 - acc: 0.8877\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 9s 51ms/step - loss: 0.2890 - acc: 0.9091\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 9s 51ms/step - loss: 0.2627 - acc: 0.9144\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 5s 26ms/step - loss: 0.2402 - acc: 0.9305\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 9s 47ms/step - loss: 0.2190 - acc: 0.9305\n",
      "21/21 [==============================] - 6s 308ms/step\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 36s 190ms/step - loss: 0.8440 - acc: 0.4492\n",
      "Epoch 2/10\n",
      "187/187 [==============================] - 9s 51ms/step - loss: 0.6065 - acc: 0.6364\n",
      "Epoch 3/10\n",
      "187/187 [==============================] - 8s 43ms/step - loss: 0.4895 - acc: 0.7701\n",
      "Epoch 4/10\n",
      "187/187 [==============================] - 10s 53ms/step - loss: 0.4193 - acc: 0.8396\n",
      "Epoch 5/10\n",
      "187/187 [==============================] - 8s 44ms/step - loss: 0.3654 - acc: 0.8770\n",
      "Epoch 6/10\n",
      "187/187 [==============================] - 8s 43ms/step - loss: 0.3199 - acc: 0.9198\n",
      "Epoch 7/10\n",
      "187/187 [==============================] - 6s 29ms/step - loss: 0.2879 - acc: 0.9251\n",
      "Epoch 8/10\n",
      "187/187 [==============================] - 13s 69ms/step - loss: 0.2569 - acc: 0.9358\n",
      "Epoch 9/10\n",
      "187/187 [==============================] - 8s 43ms/step - loss: 0.2339 - acc: 0.9519\n",
      "Epoch 10/10\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.2124 - acc: 0.9465\n",
      "21/21 [==============================] - 6s 305ms/step\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 33s 177ms/step - loss: 0.6651 - acc: 0.6064\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.4979 - acc: 0.7660\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.4245 - acc: 0.8085\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.3732 - acc: 0.8723\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.3392 - acc: 0.8989\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.3017 - acc: 0.8989\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.2696 - acc: 0.9202\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.2455 - acc: 0.9468\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.2217 - acc: 0.9681\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.2013 - acc: 0.9681\n",
      "20/20 [==============================] - 7s 345ms/step\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 33s 174ms/step - loss: 0.6333 - acc: 0.6117\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.5054 - acc: 0.7287\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.4344 - acc: 0.7979\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.3825 - acc: 0.8404\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.3441 - acc: 0.8670\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.3105 - acc: 0.8989\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.2824 - acc: 0.9362\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.2575 - acc: 0.9362\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 16s 84ms/step - loss: 0.2350 - acc: 0.9574\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.2136 - acc: 0.9734\n",
      "20/20 [==============================] - 12s 605ms/step\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 42s 221ms/step - loss: 0.6817 - acc: 0.6064\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.5249 - acc: 0.7447\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.4482 - acc: 0.8085\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.3918 - acc: 0.8617\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.3506 - acc: 0.8883\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.3159 - acc: 0.9043\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.2872 - acc: 0.9202\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.2622 - acc: 0.9362\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.2400 - acc: 0.9574\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.2203 - acc: 0.9628\n",
      "20/20 [==============================] - 11s 565ms/step\n",
      "Standardized: 83.62% (8.59%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "df=pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/'\n",
    "                    'connectionist-bench/sonar/sonar.all-data',delimiter=',',header=None)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "X = df.iloc[:,0:60].astype(float)\n",
    "Y = df.iloc[:,60]\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# evaluate baseline model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=10,batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9  ...      51      52      53      54      55      56      57      58  \\\n",
      "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
      "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
      "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
      "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
      "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
      "\n",
      "       59  60  \n",
      "0  0.0032   R  \n",
      "1  0.0044   R  \n",
      "2  0.0078   R  \n",
      "3  0.0117   R  \n",
      "4  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "Calculation running ...\n",
      "~~~~~~~~~ \n",
      "Train Larger: 80.79% (3.64%)\n"
     ]
    }
   ],
   "source": [
    "# add additional layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "df=pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/'\n",
    "                    'connectionist-bench/sonar/sonar.all-data',delimiter=',',header=None)\n",
    "print(df.head())\n",
    "\n",
    "X = df.iloc[:,0:60].astype(float)\n",
    "Y = df.iloc[:,60]\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "\n",
    "print('Calculation running ...')\n",
    "# larger model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=5, batch_size=5,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print('~~~~~~~~~','\\nTrain Larger: %.2f%% (%.2f%%)' % (results.mean()*100, results.std()*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
