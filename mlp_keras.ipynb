{
 "cells": [
  {
   "cell_type": "code",

   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/IPython/kernel/__main__.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.3863 - acc: 0.8925 - val_loss: 0.1874 - val_acc: 0.9479\n",
      "Epoch 2/5\n",
      " - 13s - loss: 0.1560 - acc: 0.9560 - val_loss: 0.1280 - val_acc: 0.9614\n",
      "Epoch 3/5\n",
      " - 8s - loss: 0.1073 - acc: 0.9696 - val_loss: 0.1010 - val_acc: 0.9700\n",
      "Epoch 4/5\n",
      " - 9s - loss: 0.0801 - acc: 0.9773 - val_loss: 0.0846 - val_acc: 0.9751\n",
      "Epoch 5/5\n",
      " - 11s - loss: 0.0608 - acc: 0.9833 - val_loss: 0.0760 - val_acc: 0.9774\n",
      "Error: 2.26%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(2017)\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from IPython.display import SVG\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.utils.visualize_util import model_to_dot, plot_model\n",
    "# load data\n",
    "input_unit_size = 28*28\n",
    "nb_classes = 10 # class size\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], input_unit_size)\n",
    "X_test = X_test.reshape(X_test.shape[0], input_unit_size)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Scale the values by dividing 255 i.e., means foreground (black)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# one-hot representation, required for multiclass problems\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "nb_classes = 10 # class size\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "input_unit_size = 28*28\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(input_unit_size, input_dim=input_unit_size, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(nb_classes, kernel_initializer='normal',activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "# model training\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=5,batch_size=500, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 4)\n",
      "(661,)\n",
      "acc: 75.11%\n",
      "acc: 76.82%\n",
      "acc: 75.00%\n",
      "75.64% (+/- 0.83%)\n"
     ]
    }
   ],
   "source": [
    "# neural network with keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "## data preparation in -> diabetes_preparation\n",
    "\n",
    "X = np.loadtxt('X.txt', delimiter=',')\n",
    "y = np.loadtxt('y.txt', delimiter=',')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# define 3-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], y[train], epochs=10, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 4)\n",
      "(661,)\n",
      "0.7702117864747468\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate Models with Cross-Validation\n",
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "## data preparation in -> diabetes_preparation\n",
    "\n",
    "X = np.loadtxt('X.txt', delimiter=',')\n",
    "y = np.loadtxt('y.txt', delimiter=',')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 4)\n",
      "(661,)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] optimizer=rmsprop, init=uniform, epochs=25, batch_size=5 ........\n",
      "[CV] optimizer=rmsprop, init=uniform, epochs=25, batch_size=5 ........\n",
      "[CV]  optimizer=rmsprop, init=uniform, epochs=25, batch_size=5, score=0.7318181934004481, total= 6.9min\n",
      "[CV] optimizer=rmsprop, init=uniform, epochs=25, batch_size=5 ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  optimizer=rmsprop, init=uniform, epochs=25, batch_size=5, score=0.7466063448881132, total= 7.0min\n",
      "[CV] optimizer=rmsprop, init=normal, epochs=35, batch_size=10 ........\n",
      "[CV]  optimizer=rmsprop, init=normal, epochs=35, batch_size=10, score=0.7601809949357046, total= 5.7min\n",
      "[CV] optimizer=rmsprop, init=normal, epochs=35, batch_size=10 ........\n",
      "[CV]  optimizer=rmsprop, init=uniform, epochs=25, batch_size=5, score=0.7863636463880539, total= 7.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed: 14.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] optimizer=rmsprop, init=normal, epochs=35, batch_size=10 ........\n",
      "[CV]  optimizer=rmsprop, init=normal, epochs=35, batch_size=10, score=0.736363638531078, total= 5.5min\n",
      "[CV] optimizer=adam, init=glorot_uniform, epochs=35, batch_size=10 ...\n",
      "[CV]  optimizer=rmsprop, init=normal, epochs=35, batch_size=10, score=0.790909083052115, total= 5.9min\n",
      "[CV] optimizer=adam, init=glorot_uniform, epochs=35, batch_size=10 ...\n",
      "[CV]  optimizer=adam, init=glorot_uniform, epochs=35, batch_size=10, score=0.7466063364598546, total= 6.9min\n",
      "[CV] optimizer=adam, init=glorot_uniform, epochs=35, batch_size=10 ...\n",
      "[CV]  optimizer=adam, init=glorot_uniform, epochs=35, batch_size=10, score=0.7318181774832986, total= 6.3min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=10 \n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=10, score=0.7466063310657691, total= 5.1min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 32.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  optimizer=adam, init=glorot_uniform, epochs=35, batch_size=10, score=0.7999999929558147, total= 6.8min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=10 \n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=10, score=0.763636364178224, total= 4.7min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=10 \n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=10, score=0.790909083052115, total= 5.0min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=10 \n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=10, score=0.751131221719457, total= 6.1min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=10 \n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=10, score=0.7454545470801267, total= 6.7min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=5 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 44.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=10, score=0.7681818130341443, total= 7.0min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=5 .\n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=5, score=0.7601810060610059, total= 8.8min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=5 .\n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=25, batch_size=5, score=0.800000009211627, total= 8.4min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=5 .\n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=5, score=0.7420814582799894, total=11.2min\n",
      "[CV] optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=5 .\n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=5, score=0.7409091022881594, total=11.2min\n",
      "[CV] optimizer=rmsprop, init=uniform, epochs=25, batch_size=10 .......\n",
      "[CV]  optimizer=rmsprop, init=uniform, epochs=25, batch_size=10, score=0.7375565605465643, total= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 78.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] optimizer=rmsprop, init=uniform, epochs=25, batch_size=10 .......\n",
      "[CV]  optimizer=rmsprop, init=glorot_uniform, epochs=35, batch_size=5, score=0.7681818296286193, total=11.7min\n",
      "[CV] optimizer=rmsprop, init=uniform, epochs=25, batch_size=10 .......\n",
      "[CV]  optimizer=rmsprop, init=uniform, epochs=25, batch_size=10, score=0.7272727299820293, total= 5.4min\n",
      "[CV] optimizer=adam, init=normal, epochs=25, batch_size=5 ............\n",
      "[CV]  optimizer=rmsprop, init=uniform, epochs=25, batch_size=10, score=0.804545449939641, total= 5.2min\n",
      "[CV] optimizer=adam, init=normal, epochs=25, batch_size=5 ............\n",
      "[CV]  optimizer=adam, init=normal, epochs=25, batch_size=5, score=0.7737556658853773, total= 9.4min\n",
      "[CV] optimizer=adam, init=normal, epochs=25, batch_size=5 ............\n",
      "[CV]  optimizer=adam, init=normal, epochs=25, batch_size=5, score=0.7227272845127366, total= 9.4min\n",
      "[CV] optimizer=adam, init=uniform, epochs=35, batch_size=5 ...........\n",
      "[CV]  optimizer=adam, init=normal, epochs=25, batch_size=5, score=0.7818181921135295, total= 9.8min\n",
      "[CV] optimizer=adam, init=uniform, epochs=35, batch_size=5 ...........\n",
      "[CV]  optimizer=adam, init=uniform, epochs=35, batch_size=5, score=0.7556561201271428, total=13.0min\n",
      "[CV] optimizer=adam, init=uniform, epochs=35, batch_size=5 ...........\n",
      "[CV]  optimizer=adam, init=uniform, epochs=35, batch_size=5, score=0.7227272845127366, total=12.8min\n",
      "[CV]  optimizer=adam, init=uniform, epochs=35, batch_size=5, score=0.8000000102276151, total=10.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 119.7min finished\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with random search via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=X.shape[1], kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "## data preparation in -> diabetes_preparation\n",
    "\n",
    "X = np.loadtxt('X.txt', delimiter=',')\n",
    "y = np.loadtxt('y.txt', delimiter=',')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "inits = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [25, 35]\n",
    "batches = [5, 10]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
    "grid = RandomizedSearchCV(model, param_grid, cv=3,verbose=10,n_jobs=-1,random_state=500)\n",
    "grid_result = grid.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
